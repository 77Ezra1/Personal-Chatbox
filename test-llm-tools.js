/**
 * å¤§æ¨¡å‹å·¥å…·è°ƒç”¨æµ‹è¯•è„šæœ¬
 * ä½¿ç”¨OpenAIå®¢æˆ·ç«¯æµ‹è¯•MCPå·¥å…·è°ƒç”¨
 */

import OpenAI from 'openai'
import { convertMcpToolsToOpenAIFormat, executeMcpTool } from './src/lib/mcpClient.js'

// ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„OpenAIé…ç½®
const client = new OpenAI()

// æ¨¡æ‹Ÿå¯ç”¨çš„æœåŠ¡å™¨é…ç½®
const enabledServers = [
  {
    id: 'duckduckgo-search',
    type: 'search',
    name: 'DuckDuckGo æœç´¢',
    isEnabled: true,
    requiresApiKey: false
  },
  {
    id: 'open-meteo-weather',
    type: 'weather', 
    name: 'Open-Meteo å¤©æ°”',
    isEnabled: true,
    requiresApiKey: false
  },
  {
    id: 'official-time-server',
    type: 'time',
    name: 'å®˜æ–¹æ—¶é—´æœåŠ¡',
    isEnabled: true,
    requiresApiKey: false
  }
]

async function testLLMWithTools() {
  console.log('ğŸ¤– å¼€å§‹æµ‹è¯•å¤§æ¨¡å‹å·¥å…·è°ƒç”¨...\n')
  
  // è½¬æ¢MCPå·¥å…·ä¸ºOpenAIæ ¼å¼
  const tools = convertMcpToolsToOpenAIFormat(enabledServers)
  console.log('âœ… å·²è½¬æ¢', tools.length, 'ä¸ªå·¥å…·ä¸ºOpenAIæ ¼å¼')
  
  // æµ‹è¯•é—®é¢˜åˆ—è¡¨
  const testQuestions = [
    "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
    "å¸®æˆ‘æœç´¢ä¸€ä¸‹æœ€æ–°çš„AIæŠ€æœ¯è¶‹åŠ¿",
    "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"
  ]
  
  for (let i = 0; i < testQuestions.length; i++) {
    const question = testQuestions[i]
    console.log(`\nğŸ“ æµ‹è¯•é—®é¢˜ ${i + 1}: ${question}`)
    
    try {
      // è°ƒç”¨å¤§æ¨¡å‹
      const response = await client.chat.completions.create({
        model: 'gpt-4.1-mini',
        messages: [
          {
            role: 'user',
            content: question
          }
        ],
        tools: tools,
        tool_choice: 'auto'
      })
      
      const message = response.choices[0].message
      
      if (message.tool_calls && message.tool_calls.length > 0) {
        console.log('ğŸ”§ å¤§æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·:', message.tool_calls.length, 'ä¸ª')
        
        // æ‰§è¡Œå·¥å…·è°ƒç”¨
        const toolResults = []
        for (const toolCall of message.tool_calls) {
          console.log('  - å·¥å…·:', toolCall.function.name)
          console.log('  - å‚æ•°:', toolCall.function.arguments)
          
          try {
            const args = JSON.parse(toolCall.function.arguments)
            const result = await executeMcpTool(toolCall.function.name, args, enabledServers)
            
            if (result.success) {
              console.log('  âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ')
              toolResults.push({
                tool_call_id: toolCall.id,
                role: 'tool',
                content: result.content
              })
            } else {
              console.log('  âŒ å·¥å…·æ‰§è¡Œå¤±è´¥:', result.error)
              toolResults.push({
                tool_call_id: toolCall.id,
                role: 'tool',
                content: `å·¥å…·æ‰§è¡Œå¤±è´¥: ${result.error}`
              })
            }
          } catch (error) {
            console.log('  âŒ å·¥å…·æ‰§è¡Œå¼‚å¸¸:', error.message)
            toolResults.push({
              tool_call_id: toolCall.id,
              role: 'tool',
              content: `å·¥å…·æ‰§è¡Œå¼‚å¸¸: ${error.message}`
            })
          }
        }
        
        // å°†å·¥å…·ç»“æœå‘é€å›å¤§æ¨¡å‹
        const finalResponse = await client.chat.completions.create({
          model: 'gpt-4.1-mini',
          messages: [
            {
              role: 'user',
              content: question
            },
            message,
            ...toolResults
          ]
        })
        
        console.log('ğŸ¯ æœ€ç»ˆå›ç­”:', finalResponse.choices[0].message.content)
        
      } else {
        console.log('ğŸ“ ç›´æ¥å›ç­”:', message.content)
      }
      
    } catch (error) {
      console.log('âŒ æµ‹è¯•å¤±è´¥:', error.message)
    }
  }
  
  console.log('\nğŸ å¤§æ¨¡å‹å·¥å…·è°ƒç”¨æµ‹è¯•å®Œæˆï¼')
}

// è¿è¡Œæµ‹è¯•
testLLMWithTools().catch(console.error)
